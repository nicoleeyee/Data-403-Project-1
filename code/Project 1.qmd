---
title: "Project 1"
format: pdf
editor: visual
---

```{r}
library(tidyverse)
library(readr)
library(here)
library(ggplot2)
library(arrow) 
library(plotly)
```

## Data Pre-processing

```{r}
# data <- read_csv(here::here("Iowa_Liquor_Sales_20250926.csv"))
data <- read_parquet(here("data", "iowa_liquor_2023_2025.parquet"))
pop <- read_csv(here("data", "pop.csv"))

head(data)
colnames(data)
str(data)
```

-   total sales for each store per month

-   store proximity / num stores in certain radius

-   efficiency - sales/pop size

-   total sales per month / num orders every month for each store -\> size of store?

-   how often are the stores ordering

-   what are they ordering most of -

-   deal w missing values

    -   check county, sales, zip codes

```{r}
data_clean <- data |>
  mutate(year = year(date),
         week = week(date),
         month = month(date),
         county = tolower(county))

head(data_clean)
```

## County Population Data

```{r}
pop <- read_csv("/Users/nicoleyee/Downloads/cc-est2024-agesex-19.csv")

pop_split <- pop |>
  mutate(CTYNAME = tolower(CTYNAME),
         name = str_extract(CTYNAME, pattern = "^[^ ]+"),
         year = case_when(
           YEAR == 1 ~ 2020,
           YEAR == 2 ~ 2020,
           YEAR == 3 ~ 2021,
           YEAR == 4 ~ 2022,
           YEAR == 5 ~ 2023,
           YEAR == 6 ~ 2024,
         ),
         over21 = POPESTIMATE-(AGE1417_TOT+AGE513_TOT+UNDER5_TOT),
         propOver21 = over21/POPESTIMATE)

write_csv(pop_split, file = here("pop.csv"))

joined <- data_clean |>
  left_join(pop, by=join_by(county==name, year == year))
head(pop_split)
```

```{r}
pop_split |>
  filter(year == 2024) |>
  slice_max(order_by=over21, n=10) |>
  arrange(over21) |>
  ggplot(aes(x=reorder(name, -over21), y=over21)) +
  geom_col() +
  theme_minimal() +
  labs(x="County", y="Population over 21")

pop_split |>
  filter(year == 2024) |>
  slice_max(order_by=propOver21, n=10) |>
  arrange(over21) |>
  ggplot(aes(x=reorder(name, -propOver21), y=propOver21)) +
  geom_col() +
  theme_minimal() +
  labs(x="County", title="Top 10 Counties with highest prop. of pop. over 21")
```

```{r}
joined |>
  filter(Year == 2024) |>
  group_by(CTYNAME) |>
  summarise(total_sales = sum(`Sale (Dollars)`)) |>
  slice_max(order_by = total_sales, n=10) |>
  ggplot(aes(x=reorder(CTYNAME, -total_sales), y=total_sales)) +
  geom_col() +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(x="County",y="Total Sales (USD)", title="Total Sales in 2024")
```

```{r}
pop_split |>
  slice_max(order_by = POPESTIMATE)
```

```{r}
proximity <- read_csv(here("data", "proximity.csv"))
```

```{r}
store_sales <- data_clean |>
  group_by(`Store Number`) |>
  summarise(sum = sum(`Sale (Dollars)`)) |>
  filter(!is.na(`Store Number`))

prox_clean <- proximity |>
  filter(store %in% store_sales$`Store Number`) |>
  left_join(store_sales, by=join_by(store==`Store Number`)) 

plot <- prox_clean |>
  filter(sum < 15000000) |>
  ggplot(aes(x=`# of stores within 5 mile radius`, y=sum, text = `store`)) +
  geom_jitter() +
  theme_minimal()
ggplotly(plot)

```

```{r}
mat <- matrix(c(1,2,3,4,5,6,7,8,9), nrow = 3)
res <- matrix(c(1,4,2,56,4,3,1,2,6), nrow = 3)
```

## Linear Regression

```{r}
lin_reg <- function(X, Y) {
  X.mat <- data.matrix(X)
  Y.mat <- data.matrix(Y)
  
  ones <- rep(1, nrow(X))
  
  X.mat <- cbind(ones, X.mat)
  
  B <- solve(t(X.mat)%*%X.mat)%*%(t(X.mat)%*%Y.mat)
  
  return(B)
}
```

```{r}
predict <- function(X, B){
  ones <- rep(1, nrow(X))
  X <- data.matrix(X)
  X.mat <- cbind(ones, X)
  
  Y.hat <- X.mat%*%B
  
  return(as.data.frame(Y.hat))
}
```

## Cross Validation

```{r}
cv <- function(data, predictors, response, num_splits){

  n <- nrow(data)
  folds <- base::sample(rep(1:num_splits, length.out = n))
  
  results <- tibble()
  
  for(i in 1:num_splits){
    test <- which(folds == i)
    X_train <- data[-test, predictors, drop = FALSE]
    Y_train <- data[-test, response, drop= FALSE]
    
    X_test <- data[test, predictors, drop=FALSE]
    Y_test <- as.data.frame(data[test, response])
    
    B <- lin_reg(X_train, Y_train)
    
    Y_hat <- predict(X_test, B)
    # return(Y_hat)
    # print(Y_hat[1:5,])
    # print(Y_test[1:5,])
    split_metrics <- metrics(predictors, as.data.frame(Y_test), Y_hat) |>
      mutate(split = i)
    
    results <- bind_rows(results, split_metrics)
  }
  
  out <- results |>
    summarise(across(c(R2, AR2, MAE, RMSE), mean))
  return(out)
}
```

## Metrics

```{r}
metrics <- function(predictors, Y, pred){
  # return(Y-pred)
  n <- nrow(Y)
  p <- length(predictors) + 1
  ssr <- sum((Y[,1]-pred[,1])^2)
  sst <- sum((Y[,1]-mean(Y[,1]))^2)
  
  rsq <- 1- ssr/sst
  adjrsq <- 1-(1-rsq)*(n-1)/(n-p)
  
  mae <- mean(abs(Y[,1]-pred[,1]))
  
  rmse <- sqrt(ssr/n)
  
  out <- tibble(R2 = rsq,
                AR2 = adjrsq,
                MAE = mae,
                RMSE = rmse)
  
  return(out)
}
```

## Testing

```{r}
s1 <- joined |>
  group_by(county, week, month, year) |>
  # summarise(avg_sales = mean(sale_dollars)) |>
  mutate(avg_sales = mean(sale_dollars),
    per_person = avg_sales/POPESTIMATE,
         propsex = POPEST_MALE/POPEST_FEM,
         propteen = AGE1417_TOT/POPESTIMATE,
         propcollege = AGE1824_TOT/POPESTIMATE) |>
  ungroup()
predictors <- c("month", "over21", "propsex", "propteen", "propcollege")
response <- "per_person"
```

```{r}
cv(s1[1:200,], predictors, response, 5)
```
